2025-03-07 22:05:31 Training with configuration:
2025-03-07 22:05:31 data:
2025-03-07 22:05:31   colormode: RGB
2025-03-07 22:05:31   inference:
2025-03-07 22:05:31     normalize_images: True
2025-03-07 22:05:31   train:
2025-03-07 22:05:31     affine:
2025-03-07 22:05:31       p: 0.5
2025-03-07 22:05:31       rotation: 30
2025-03-07 22:05:31       scaling: [0.5, 1.25]
2025-03-07 22:05:31       translation: 0
2025-03-07 22:05:31     covering: False
2025-03-07 22:05:31     crop_sampling:
2025-03-07 22:05:31       width: 448
2025-03-07 22:05:31       height: 448
2025-03-07 22:05:31       max_shift: 0.1
2025-03-07 22:05:31       method: hybrid
2025-03-07 22:05:31     gaussian_noise: 12.75
2025-03-07 22:05:31     hist_eq: False
2025-03-07 22:05:31     motion_blur: False
2025-03-07 22:05:31     normalize_images: True
2025-03-07 22:05:31 device: auto
2025-03-07 22:05:31 metadata:
2025-03-07 22:05:31   project_path: /content/extracted_files/social_exp-jake-2025-01-31
2025-03-07 22:05:31   pose_config_path: /content/extracted_files/social_exp-jake-2025-01-31/dlc-models-pytorch/iteration-0/social_expJan31-trainset95shuffle1/train/pytorch_config.yaml
2025-03-07 22:05:31   bodyparts: ['nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear', 'mid_back', 'tail_base']
2025-03-07 22:05:31   unique_bodyparts: []
2025-03-07 22:05:31   individuals: ['adult', 'juvie']
2025-03-07 22:05:31   with_identity: False
2025-03-07 22:05:31 method: bu
2025-03-07 22:05:31 model:
2025-03-07 22:05:31   backbone:
2025-03-07 22:05:31     type: ResNet
2025-03-07 22:05:31     model_name: resnet50_gn
2025-03-07 22:05:31     output_stride: 16
2025-03-07 22:05:31     freeze_bn_stats: False
2025-03-07 22:05:31     freeze_bn_weights: False
2025-03-07 22:05:31   backbone_output_channels: 2048
2025-03-07 22:05:31   heads:
2025-03-07 22:05:31     bodypart:
2025-03-07 22:05:31       type: DLCRNetHead
2025-03-07 22:05:31       predictor:
2025-03-07 22:05:31         type: PartAffinityFieldPredictor
2025-03-07 22:05:31         num_animals: 2
2025-03-07 22:05:31         num_multibodyparts: 7
2025-03-07 22:05:31         num_uniquebodyparts: 0
2025-03-07 22:05:31         nms_radius: 5
2025-03-07 22:05:31         sigma: 1.0
2025-03-07 22:05:31         locref_stdev: 7.2801
2025-03-07 22:05:31         min_affinity: 0.05
2025-03-07 22:05:31         graph: [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [2, 3], [2, 4], [2, 5], [2, 6], [3, 4], [3, 5], [3, 6], [4, 5], [4, 6], [5, 6]]
2025-03-07 22:05:31         edges_to_keep: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
2025-03-07 22:05:31         apply_sigmoid: True
2025-03-07 22:05:31         clip_scores: False
2025-03-07 22:05:31       target_generator:
2025-03-07 22:05:31         type: SequentialGenerator
2025-03-07 22:05:31         generators: [{'type': 'HeatmapPlateauGenerator', 'num_heatmaps': 7, 'pos_dist_thresh': 17, 'heatmap_mode': 'KEYPOINT', 'gradient_masking': False, 'generate_locref': True, 'locref_std': 7.2801}, {'type': 'PartAffinityFieldGenerator', 'graph': [[0, 1], [0, 2], [0, 3], [0, 4], [0, 5], [0, 6], [1, 2], [1, 3], [1, 4], [1, 5], [1, 6], [2, 3], [2, 4], [2, 5], [2, 6], [3, 4], [3, 5], [3, 6], [4, 5], [4, 6], [5, 6]], 'width': 20}]
2025-03-07 22:05:31       criterion:
2025-03-07 22:05:31         heatmap:
2025-03-07 22:05:31           type: WeightedBCECriterion
2025-03-07 22:05:31           weight: 1.0
2025-03-07 22:05:31         locref:
2025-03-07 22:05:31           type: WeightedHuberCriterion
2025-03-07 22:05:31           weight: 0.05
2025-03-07 22:05:31         paf:
2025-03-07 22:05:31           type: WeightedHuberCriterion
2025-03-07 22:05:31           weight: 0.1
2025-03-07 22:05:31       heatmap_config:
2025-03-07 22:05:31         channels: [2048, 7]
2025-03-07 22:05:31         kernel_size: [3]
2025-03-07 22:05:31         strides: [2]
2025-03-07 22:05:31       locref_config:
2025-03-07 22:05:31         channels: [2048, 14]
2025-03-07 22:05:31         kernel_size: [3]
2025-03-07 22:05:31         strides: [2]
2025-03-07 22:05:31       paf_config:
2025-03-07 22:05:31         channels: [2048, 42]
2025-03-07 22:05:31         kernel_size: [3]
2025-03-07 22:05:31         strides: [2]
2025-03-07 22:05:31       num_stages: 5
2025-03-07 22:05:31 net_type: resnet_50
2025-03-07 22:05:31 runner:
2025-03-07 22:05:31   type: PoseTrainingRunner
2025-03-07 22:05:31   gpus: None
2025-03-07 22:05:31   key_metric: test.mAP
2025-03-07 22:05:31   key_metric_asc: True
2025-03-07 22:05:31   eval_interval: 10
2025-03-07 22:05:31   optimizer:
2025-03-07 22:05:31     type: AdamW
2025-03-07 22:05:31     params:
2025-03-07 22:05:31       lr: 0.001
2025-03-07 22:05:31   scheduler:
2025-03-07 22:05:31     type: LRListScheduler
2025-03-07 22:05:31     params:
2025-03-07 22:05:31       lr_list: [[0.0001], [1e-05]]
2025-03-07 22:05:31       milestones: [90, 120]
2025-03-07 22:05:31   snapshots:
2025-03-07 22:05:31     max_snapshots: 5
2025-03-07 22:05:31     save_epochs: 5
2025-03-07 22:05:31     save_optimizer_state: False
2025-03-07 22:05:31 train_settings:
2025-03-07 22:05:31   batch_size: 8
2025-03-07 22:05:31   dataloader_workers: 0
2025-03-07 22:05:31   dataloader_pin_memory: False
2025-03-07 22:05:31   display_iters: 500
2025-03-07 22:05:31   epochs: 11
2025-03-07 22:05:31   seed: 42
2025-03-07 22:05:32 Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)
2025-03-07 22:05:33 [timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
2025-03-07 22:05:34 Data Transforms:
2025-03-07 22:05:34   Training:   Compose([
  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),
  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),
  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),
  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-03-07 22:05:34   Validation: Compose([
  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),
], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)
2025-03-07 22:05:39 Using 4499 images and 237 for testing
2025-03-07 22:05:39 
Starting pose model training...
--------------------------------------------------
2025-03-07 22:10:28 Number of iterations: 500, loss: 0.00661, lr: 0.001
2025-03-07 22:11:03 Epoch 1/11 (lr=0.001), train loss 0.01258
2025-03-07 22:15:49 Number of iterations: 500, loss: 0.00489, lr: 0.001
2025-03-07 22:16:24 Epoch 2/11 (lr=0.001), train loss 0.00690
2025-03-07 22:21:10 Number of iterations: 500, loss: 0.00601, lr: 0.001
2025-03-07 22:21:46 Epoch 3/11 (lr=0.001), train loss 0.00576
2025-03-07 22:26:32 Number of iterations: 500, loss: 0.00538, lr: 0.001
2025-03-07 22:27:08 Epoch 4/11 (lr=0.001), train loss 0.00539
2025-03-07 22:31:55 Number of iterations: 500, loss: 0.00623, lr: 0.001
2025-03-07 22:32:31 Epoch 5/11 (lr=0.001), train loss 0.00512
2025-03-07 22:37:16 Number of iterations: 500, loss: 0.00535, lr: 0.001
2025-03-07 22:37:52 Epoch 6/11 (lr=0.001), train loss 0.00500
2025-03-07 22:42:38 Number of iterations: 500, loss: 0.00452, lr: 0.001
2025-03-07 22:43:15 Epoch 7/11 (lr=0.001), train loss 0.00485
2025-03-07 22:48:01 Number of iterations: 500, loss: 0.00313, lr: 0.001
2025-03-07 22:48:37 Epoch 8/11 (lr=0.001), train loss 0.00479
2025-03-07 22:53:23 Number of iterations: 500, loss: 0.00548, lr: 0.001
2025-03-07 22:53:59 Epoch 9/11 (lr=0.001), train loss 0.00464
2025-03-07 22:58:46 Number of iterations: 500, loss: 0.00476, lr: 0.001
2025-03-07 22:59:22 Training for epoch 10 done, starting evaluation
2025-03-07 23:00:17 Epoch 10/11 (lr=0.001), train loss 0.00458, valid loss 0.00378
2025-03-07 23:00:17 Model performance:
2025-03-07 23:00:17   metrics/test.rmse:          14.28
2025-03-07 23:00:17   metrics/test.rmse_pcutoff:  10.83
2025-03-07 23:00:17   metrics/test.mAP:           58.05
2025-03-07 23:00:17   metrics/test.mAR:           62.36
2025-03-07 23:05:02 Number of iterations: 500, loss: 0.00494, lr: 0.001
2025-03-07 23:05:38 Epoch 11/11 (lr=0.001), train loss 0.00452
